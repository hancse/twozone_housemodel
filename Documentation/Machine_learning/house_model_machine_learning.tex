\input{preamble}

%Document title, author and date (empty)
\title{House model machine learning}
\author{Marijn Jongerden\\
HAN University of Applied Sciences\\
Arnhem, The Netherlands}
% \date{}

\begin{document}
	
\ldf  % Set LaTeX default font

% Set up code listing style:
\lstset{
	language=Python,
	% Fonts:
	basicstyle=\ttfamily\footnotesize,
	%keywordstyle=\ttfamily,
	%identifierstyle=,
	%commentstyle=\ttfamily\scriptsize,
	% B/W code:
	% commentstyle=\ttfamily\itshape,  % Italic
	% stringstyle=\ttfamily,
	% identifierstyle=\ttbf,           % Bold typewriter type
	% keywordstyle=\ttbf,              % Bold tt
	% Colour:
	commentstyle=\scriptsize\ttfamily\color{brown},
	stringstyle=\ttfamily\color{darkgreen},
	identifierstyle=\color{blue},
	keywordstyle=\ttfamily\color{red},
	% Spaces:
	showstringspaces=false,
	breaklines=true,
	breakatwhitespace=true,
	% Line numbering:
	numbers=left,
	numberstyle=\tiny,
	stepnumber=2, 
	numbersep=5pt,
	% Frames:
	frame=single,
	frameround=tttt,
	backgroundcolor=\color{lightgrey},
	morekeywords={pthread_create},
}
%\renewcommand{\thelstlisting}{\thechapter.\arabic{lstlisting}}  % This is the default?
%\numberwithin{lstlisting}{section}  % AMSmath: number code listings per section
%\numberwithin{lstlisting}{chapter}  % AMSmath: number code listings per chapter

\ldf

\maketitle


%\begin{center}
%	\today
%\end{center}

%\tableofcontents

%\newpage

\section{Introduction}\label{s:introduction}
The developed house model (put a ref here) allows to simulate the heating process of a given house. Based on weather information such as the outside temperature and solar irradiation, house specifications, and other input factors it is possible to compute the details on the temperature evolution. 

The model needs many details to run. These details will be hard to get a hold of in practice.

It would be interesting to see whether it is possible to use machine learning to abstract from the details of that are used to create the model and use only limited amount of input data to create a model that can predict the heat demand of a house. 

 


%\section{Background}\label{s:background}


\section{Machine learning approach}\label{s:MLA}
Intro to the section...

\subsection{LSTM network}
We create a Long short-term memory (LSTM) network for predicting the heat demand. An LSTM network is a type of recurrent neural network (RNN). These models are widely used in, for example, the field of speech recognition, language modeling, machine translation. LSTM networks are also well suited for time series data, as we have here. In a RNN the output of a layer in the network can be fed back to be used as input of an earlier layer in the network. In this way, dependencies on the data history can be taken into account in the model. LSTM networks are a specific type of RNNs, designed such that the network learns which historical data is needed to \"remember\" using the memory cell, and which data can be \"forgotten\" using a so-termed forget-gate, in order to predict the next output. More details on the working of the LSTM can be found in \ref{}. 

The full network that will be used consists of an LSTM-layer, that is used to learn the dependencies on the historic data, and a fully connected linear layer that applies a linear transformation to the output from the LSTM-layer to obtain the final output.  



\subsection{input data selection}

In this first exploration of the potential of using a machine learning model to predict the heat demand of a household we make use of data generated with the house model. The house model provides a heat demand profile for a full year. The heat demand is based on weather data, temperature and solar irradiation, construction parameters of the house, and some behavioral parameters, such as the number of people present in the house and the thermostat setting.   

The model is described in detail in \ref{}. The house is modeled as a network of heat capacitors, between which energy can be exchanged. The most simple house model uses 2 heat capacitors, one for the air in the house and one for the walls. Heat can be exchanged between the two capacitors, and the outside air. Essentially this model approximates the house as a single compartment with its walls. 

A more detailed representation of the house can be made by using multiple heat capacitors, for example one for each floor or room.   
Several versions of the specific model have been developed. Initially we make use of the data generated by the Matlab-Simulink implementation, which has a time granularity of one hour. Later we shift to the more detailed Python implementation of the model, which has more flexibility and a higher time granularity.

The input features we want to use for our model should also be easily available in practice. The input features we select to create our model are:
\begin{itemize}
\item Outside temperature ($T_{out}$); we can assume this parameter is easily available through either a local thermometer or an online service providing data of a nearby weather station. Alternatively weather forecast date might be used. 
\item temperature of the house ($T_{house}$); this should be available through the thermostat. In the house model this is the temperature of air. In case of a model that has multiple compartments, we use the air temperature of the main compartment.
\item thermostat set point ($SP$), this should be available though the thermostat. Potentially, these values are even available for future values, since often programs are created to set the thermostat values. 
\item solar irradiation ($Q_{solar}$), although these values may not be straightforward to obtain for a specific location, an estimate value may be obtained from a local weather station. 
\item heat demand ($Q_{demand}$), the historic values of the heat demand will be used to predict the future values. 
\end{itemize}

More features could be available from the house model, such as the heat generated by the appliances and inhabitants or the temperature of the walls. However, not all of these will be practically available. We hope to obtain a machine learned model that can abstract from these details and still give a good prediction for the heat demand for the coming time period. When much data from the house model is needed, it is unrealistic the machine learned model could be transferred to a scenario where it works with real life data.  

\textit{NOTE: It might be interesting to also look at the capabilities to predict the house temperature as well. For the other inputs a future value may be obtained from either the weather forecast or the thermostat program. Taking the temperature predictions into account might be helpful for a model predictive control approach?}

\subsection{data preprocessing steps}
The input data is loaded from an Excel sheet that contains all the hourly values. When we want to create a model the data needs to be spit in a training and a test set. As we are dealing with a time series the order of the data needs to be retained. The first $70\%$ of the data will be used for training the mode and the last $30\%$ will be used for testing. 

Next to splitting the data, the data set needs to be normalized, by subtracting the mean of all feature values ($\mu$) and dividing by the standard deviation ($\sigma$) (using the standardscaler),$x_{norm}= \frac{x-\mu}{\sigma}$. The output is normalized as well.

After the normalization of the data, the data needs to be prepared for the LSTM. From the data a set of sequences is created. For each output value, heat demand at time $t$, a sequence of historical data of input values is needed, time steps $t-N \cdots t-1$.  

(\textit{NOTE: the value of N, the number of historical time steps needs to be determined. For the hourly data $N=12$ seems to give good results. A logical choice would be to set $N$ such that 24 hours of historical data is used to predict the next time step, since a high correlation with 24 hours earlier is to be expected. The actual number of time steps depends on the time granularity of the data. 

One may also reason that the heat demand for the next hour is mainly determined by the temperatures and the thermostat setting of the last hour. This implies little history is actually needed. })

\subsection{model training}
For training the model we pass all input data through the network, 

\begin{itemize}
\item What are the options for settings for the learning process?
\item adam learning algorithm
\item number of epochs
\item \ldots
\end{itemize}

\subsection{model testing}
\begin{itemize}
\item data prep, scaling \+ sequencing
\item model use
\item back scaling output
\end{itemize}


\section{Python implementation}
 various functions

\subsection{LSTM-layer}
The key parameters that need to be defined for the LSTM-layer are:
\begin{itemize}
\item input_size: the number of input features used for the layer.
\item hidden_size: the number of features in the hidden state.
\end{itemize}
All other parameters, such as, num_layers, bias, etc, will be used in the default setting. 





\section{results}
analysis for the choice of sequence length, and other parameters.

quality of the model based on MSE on the test set. 




\section{discussion}


%\bibliography{mybibliography}
%\printbibliography[heading=bibintoc]

\end{document}
